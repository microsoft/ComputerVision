{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Multi-Object Tracking Model on MOT Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for evaluating [FairMOT](https://github.com/ifzhang/FairMOT) on the [MOT Challenge dataset](https://motchallenge.net/), one of the most common benchmarking datasets for measuring multi-object tracking performance on pedestrian data. The collection includes MOT15, MOT16/17, and MOT 19/20. These datasets contain various video sequences, each with different tracking difficulty levels and ground-truth annotations. Detections are also provided for optional use.\n",
    "\n",
    "The goal of this notebook is to re-produce published results on the MOT challenge using the state-of-the-art FairMOT approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure edits to libraries are loaded and plotting is shown in the notebook.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchVision: 0.4.0a0+6b959ee\n",
      "Torch is using GPU: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from urllib.parse import urljoin\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from utils_cv.common.data import data_path, download, unzip_url\n",
    "from utils_cv.common.gpu import which_processor, is_windows\n",
    "from utils_cv.tracking.data import Urls\n",
    "from utils_cv.tracking.dataset import TrackingDataset\n",
    "from utils_cv.tracking.model import TrackingLearner\n",
    "\n",
    "# Change matplotlib backend so that plots are shown for windows\n",
    "if is_windows():\n",
    "    plt.switch_backend(\"TkAgg\")\n",
    "\n",
    "print(f\"TorchVision: {torchvision.__version__}\")\n",
    "which_processor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows your machine's GPUs (if it has any) and the computing device `torch/torchvision` is using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set some model runtime parameters. We evaluate the FairMOT model on MOT17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch device: cuda\n"
     ]
    }
   ],
   "source": [
    "CONF_THRES = 0.4\n",
    "TRACK_BUFFER = 30\n",
    "IM_SIZE = (1080, 1920)\n",
    "\n",
    "# Downloaded MOT Challendage data path\n",
    "MOT_ROOT_PATH = \"../../data/\"\n",
    "RESULT_ROOT = \"./results\"\n",
    "EXP_NAME = \"MOT_val_all_dla34\"\n",
    "\n",
    "BASELINE_MODEL = \"./models/all_dla34.pth\"\n",
    "MOTCHALLENGE_BASE_URL = \"https://motchallenge.net/data/\"\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using torch device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Dataset Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [MOT17](https://motchallenge.net/data/MOT17.zip) data to `MOT_SAVED_PATH`. The MOT17 dataset is around 5GB. Note that it may take some time to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved to ../../data/MOT17/train\n",
      "Test data saved to ../../data/MOT17/test\n"
     ]
    }
   ],
   "source": [
    "mot_path = urljoin(MOTCHALLENGE_BASE_URL, \"MOT17.zip\")\n",
    "mot_train_path = osp.join(MOT_ROOT_PATH, \"MOT17\", \"train\")\n",
    "mot_test_path = osp.join(MOT_ROOT_PATH, \"MOT17\", \"test\")\n",
    "# seqs_str:  various video sequences subfolder names under MOT challenge data\n",
    "train_seqs = [\n",
    "    \"MOT17-02-SDP\",\n",
    "    \"MOT17-04-SDP\",\n",
    "    \"MOT17-05-SDP\",\n",
    "    \"MOT17-09-SDP\",\n",
    "    \"MOT17-10-SDP\",\n",
    "    \"MOT17-11-SDP\",\n",
    "    \"MOT17-13-SDP\",\n",
    "]\n",
    "test_seqs = [\n",
    "    \"MOT17-01-SDP\",\n",
    "    \"MOT17-03-SDP\",\n",
    "    \"MOT17-06-SDP\",\n",
    "    \"MOT17-07-SDP\",\n",
    "    \"MOT17-08-SDP\",\n",
    "    \"MOT17-12-SDP\",\n",
    "    \"MOT17-14-SDP\",\n",
    "]\n",
    "\n",
    "unzip_url(mot_path, dest=MOT_ROOT_PATH, exist_ok=True)\n",
    "print(f\"Training data saved to {mot_train_path}\")\n",
    "print(f\"Test data saved to {mot_test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and load the model. We use the pre-trained baseline FairMOT model - `all_dla34.pth`, which can be downloaded [here](https://drive.google.com/file/d/1udpOPum8fJdoEQm6n0jsIgMMViOMFinu/view). Please upload and save `all_dla34.pth` to `BASELINE_MODEL` path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = TrackingLearner(None, BASELINE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOT17 only comes with ground truth annotations for the training set, but not for the test set. We use the training set to evaluate FairMOT by [py-motmetrics](https://github.com/cheind/py-motmetrics). For the test set, you can upload results to [MOT evaluation server](https://motchallenge.net/instructions/) which returns the various evaluation metrics. Details are shown in 'Evaluate on Test Set' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-02-SDP.txt\n",
      "Evaluate seq: MOT17-02-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-04-SDP.txt\n",
      "Evaluate seq: MOT17-04-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-05-SDP.txt\n",
      "Evaluate seq: MOT17-05-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-09-SDP.txt\n",
      "Evaluate seq: MOT17-09-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-10-SDP.txt\n",
      "Evaluate seq: MOT17-10-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-11-SDP.txt\n",
      "Evaluate seq: MOT17-11-SDP\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-13-SDP.txt\n",
      "Evaluate seq: MOT17-13-SDP\n",
      "              IDF1   IDP   IDR  Rcll  Prcn  GT  MT  PT ML    FP    FN IDs    FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT17-02-SDP 60.1% 68.9% 53.3% 72.3% 93.4%  62  28  25  9   950  5148 243   628 65.9% 0.198 138  49  16\n",
      "MOT17-04-SDP 83.2% 85.1% 81.2% 86.3% 90.4%  83  51  21 11  4348  6526  32   219 77.1% 0.172   6  20   1\n",
      "MOT17-05-SDP 73.1% 75.5% 70.9% 83.9% 89.2% 133  74  50  9   702  1117 120   217 72.0% 0.221 100  45  41\n",
      "MOT17-09-SDP 65.9% 71.6% 61.0% 81.5% 95.7%  26  18   8  0   197   984  45   105 77.0% 0.175  34  10   7\n",
      "MOT17-10-SDP 63.5% 68.4% 59.2% 79.0% 91.3%  57  30  27  0   970  2700 182   439 70.0% 0.233 109  44  14\n",
      "MOT17-11-SDP 82.2% 82.0% 82.4% 92.3% 91.9%  75  55  16  4   764   722  75   112 83.5% 0.171  29  34   9\n",
      "MOT17-13-SDP 64.6% 65.9% 63.3% 77.2% 80.3% 110  50  51  9  2203  2658 164   457 56.8% 0.279  97  39  42\n",
      "OVERALL      73.9% 77.5% 70.7% 82.3% 90.1% 546 306 198 42 10134 19855 861  2177 72.5% 0.196 513 241 130\n"
     ]
    }
   ],
   "source": [
    "strsummary = tracker.eval_mot(\n",
    "    conf_thres=CONF_THRES,\n",
    "    track_buffer=TRACK_BUFFER,\n",
    "    im_size=IM_SIZE,\n",
    "    data_root=mot_train_path,\n",
    "    seqs=train_seqs,\n",
    "    result_root=RESULT_ROOT,\n",
    "    exp_name=EXP_NAME,\n",
    ")\n",
    "print(strsummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reported evaluation results from [FairMOT paper](https://arxiv.org/abs/2004.01888) with test set are as follows:\n",
    "\n",
    "| Dataset | MOTA   | IDF1 | IDS | MT | ML | FPS |\n",
    "|------|------|------|------|------|------|------|\n",
    "|   MOT16  | 68.7| 70.4| 953| 39.5%| 19.0%| 25.9|\n",
    "|   MOT17  | 67.5| 69.8| 2868| 37.7%| 20.8%| 25.9|\n",
    "\n",
    "For evaluating on testing dataset, you can get the txt prediction results in this section and submit to the [MOT Challenge](https://motchallenge.net/) evaluation server to obtain the results. You can get the SOTA results 68.5 MOTA on MOT17 test set using the baseline model 'all_dla34.pth' from the [MOT17 evaluation server](https://motchallenge.net/results/MOT17/?det=Private).\n",
    "<img src=\"media/mot_results.PNG\" style=\"width: 737.5px;height: 365px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-01-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-03-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-06-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-07-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-08-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-12-SDP.txt\n",
      "Saved tracking results to ./results/MOT_val_all_dla34/MOT17-14-SDP.txt\n"
     ]
    }
   ],
   "source": [
    "tracker.eval_mot(\n",
    "    conf_thres=CONF_THRES,\n",
    "    track_buffer=TRACK_BUFFER,\n",
    "    im_size=IM_SIZE,\n",
    "    data_root=mot_test_path,\n",
    "    seqs=test_seqs,\n",
    "    result_root=RESULT_ROOT,\n",
    "    exp_name=EXP_NAME,\n",
    "    run_eval=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "356.263px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
