{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image annotation UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open-source annotation tools for object detection and for image segmentation exist, however for image classification we were not able to find a good program. Hence this notebook provides a simple UI to label images. Each image can be annotated with one or multiple classes, or marked as \"Exclude\" to indicate that the image should not be used for model training or evaluation. \n",
    "\n",
    "Note that, for single class annotation tasks, one does not need any UI but can instead simply drag-and-drop images into separate folder for the respective classes. \n",
    "\n",
    "See the [FAQ.md](..\\FAQ.md) for a brief discussion on how to scrape images from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure edits to libraries are loaded and plotting is shown in the notebook.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "from utils_ic.anno_utils import AnnotationWidget\n",
    "from utils_ic.datasets import unzip_url, Urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters: location of the images to annotate, and path where to save the annotations. Here `unzip_url` is used to download example data if not already present, and set the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using images in directory: C:\\Users\\pabuehle\\Desktop\\ComputerVisionBestPractices\\image_classification\\data\\fridgeObjects\\can.\n"
     ]
    }
   ],
   "source": [
    "IM_DIR = os.path.join((unzip_url(Urls.fridge_objects_path, exist_ok=True)), 'can')\n",
    "ANNO_PATH = \"cvbp_ic_annotation.txt\"\n",
    "print(f\"Using images in directory: {IM_DIR}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the UI. Check the \"Allow multi-class labeling\" box to allow for images to be annotated with multiple classes. When in doubt what the annotation for an image should be, or for any other reason (e.g. blur or over-exposure), mark an image as \"EXCLUDE\". All annotations are saved to (and loaded from) a pandas dataframe with path specified in `anno_path`. \n",
    "\n",
    "<center>\n",
    "<img src=\"media/anno_ui.jpg\" style=\"width: 600px;\"/>\n",
    "<i>Annotation UI example</i>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing annotation from cvbp_ic_annotation.txt.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492cae0bb3e340babb935f688660d11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HBox(children=(Button(description='Previous', layout=Layout(width='80px'), style=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_anno_ui = AnnotationWidget(\n",
    "    labels       = [\"can\", \"carton\", \"milk_bottle\", \"water_bottle\"],\n",
    "    im_dir       = IM_DIR,\n",
    "    anno_path    = ANNO_PATH,\n",
    "    im_filenames = None #Set to None to annotate all images in IM_DIR\n",
    ")\n",
    "\n",
    "display(w_anno_ui.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example how to create a fast.ai ImageList object using the ground truth annotations generated by the AnnotationWidget. Note that fast.ai does not support the exclude flag, hence we remove these images before calling fast.ai's `from_df()` and `label_from_df()` functions.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from fastai.vision import ImageList,ImageDataBunch\n",
    "\n",
    "# Load annotation, discard excluded images, and convert to format fastai expects\n",
    "data = []\n",
    "with open(ANNO_PATH,'r') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        vec = line.strip().split(\"\\t\")\n",
    "        exclude = vec[1]==\"True\"\n",
    "        if not exclude and len(vec)>2:\n",
    "            data.append((vec[0], vec[2]))\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"name\", \"label\"])\n",
    "display(df)\n",
    "\n",
    "data = (ImageList.from_df(path=IM_DIR, df = df)\n",
    "       .split_by_rand_pct(valid_pct=0.5)\n",
    "       .label_from_df(cols='label', label_delim=','))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cvbp)",
   "language": "python",
   "name": "cvbp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
